{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: #FF6D6B\">\n",
    "\n",
    "#### Resources\n",
    "</span>\n",
    "\n",
    "- [Link to source - Cohere Docs](https://docs.cohere.com/docs/validating-outputs#wrap-an-llm-call-with-the-guard-object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: #FF6D6B\">\n",
    "\n",
    "#### Dependencies\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install cohere guardrails-ai -q\n",
    "# !guardrails hub install hub://guardrails/valid_range\n",
    "# !guardrails hub install hub://guardrails/valid_choices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: #FF6D6B\">\n",
    "\n",
    "#### Imports\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cohere\n",
    "import guardrails as gd\n",
    "from guardrails.hub import ValidRange, ValidChoices\n",
    "from pydantic import BaseModel, Field\n",
    "from rich import print\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: #FF6D6B\">\n",
    "\n",
    "#### Create a Cohere Client\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "co = cohere.Client(api_key=\"COHERE_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: #FF6D6B\">\n",
    "\n",
    "#### Create a Pydantic class to validate\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: #30AADD\">\n",
    "\n",
    "##### Simple Class\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Overview(BaseModel):\n",
    "    topic: str = Field(..., description=\"Identify the main topic that the user is asking about\", validators=[ValidChoices(topics,on_fail=\"reask\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: #30AADD\">\n",
    "\n",
    "##### Nested Class\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Topics(BaseModel):\n",
    "        topic: str = Field(..., description=f\"{subtopic_description_final}\", validators=[ValidChoices(final_list_of_subtopics,on_fail=\"reask\")])\n",
    "        subTopics: List[str] = Field(..., description=f\"Labels for the topic. For example, {labels_description_final}\")\n",
    "        others_tagging: str = Field(..., description=\"If the topic is **Others**, give a two word description of the topic. Otherwise, write NA.\")\n",
    "    \n",
    "\n",
    "    class Overview(BaseModel):\n",
    "        title: str = Field(..., description=\"Title of the content, keep it concise and within 1 line. It should be a statement that helps the user easily identify their conversations between a large language model.\")\n",
    "        shortSummary: str = Field(..., description=\"2 line description of the overall content covering the keys points in the users query and the solution given by a large language model.\")\n",
    "        detailedSummary: str = Field(..., description=\"Detailed description of the overall content within 500 words covering the keys points in the users query and the solution given by a large language model.\")\n",
    "        topics: List[Topics] = Field(..., description=f\"Identify the primary topic within the theme - {theme} ({theme_description_final}). Only focus on the question asked by the user and the topics it covers.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: #FF6D6B\">\n",
    "\n",
    "#### Define the Prompt\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT = \"\"\"Given the following conversation between a user and an answer engine,\n",
    "please identify the topic the users query belongs to and return a dictionary with the following:\n",
    "\n",
    "${convo}\n",
    "\n",
    "${gr.complete_json_suffix_v2}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: #FF6D6B\">\n",
    "\n",
    "#### Create a Guard object\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "guard = gd.Guard.from_pydantic(Overview, prompt=PROMPT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: #FF6D6B\">\n",
    "\n",
    "#### Invoke the Cohere Client\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = guard(\n",
    "    co.chat,\n",
    "    prompt_params={\"convo\": text},\n",
    "    model='command-r-plus',\n",
    "    temperature=0,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.1.-1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
